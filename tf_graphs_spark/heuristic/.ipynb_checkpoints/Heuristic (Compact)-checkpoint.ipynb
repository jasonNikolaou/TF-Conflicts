{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69699e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxpy as cp\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "import networkx as nx\n",
    "from networkx.algorithms import bipartite\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import random\n",
    "import pickle\n",
    "from time import time\n",
    "from dsd import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80529530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter GURO_PAR_SPECIAL\n",
      "Set parameter TokenServer to value \"sccsvc\"\n",
      "number of nodes: 8438\n",
      "number of (conflict) edges: 35598\n",
      "number of projects: 4772\n"
     ]
    }
   ],
   "source": [
    "input_file = './yahoo.pickle'\n",
    "pipageSetting = \"randomized\"\n",
    "\n",
    "env = gp.Env(empty=True)\n",
    "# env.setParam(\"Threads\", 16)\n",
    "# env.setParam(\"OutputFlag\",0) # suppress gurobi console output\n",
    "env.start()\n",
    "timeLimit = 1000\n",
    "\n",
    "times = dict() # dictionary to keep time for different stages\n",
    "start = time()\n",
    "# Read graph\n",
    "with open(input_file, 'rb') as file:\n",
    "    projects = pickle.load(file)\n",
    "    capacities = pickle.load(file)\n",
    "    numOfProjects = len(capacities)\n",
    "    c = pickle.load(file)\n",
    "    w = pickle.load(file)\n",
    "    edges = pickle.load(file)\n",
    "\n",
    "G = nx.Graph()\n",
    "G.add_edges_from(edges)\n",
    "nodes = list(G.nodes)\n",
    "n = len(nodes)\n",
    "max_capacity = max(capacities.values())\n",
    "\n",
    "# print(f'projects = {projects}')\n",
    "print(f'number of nodes: {n}')\n",
    "print(f'number of (conflict) edges: {len(edges)}')\n",
    "print(f'number of projects: {numOfProjects}')\n",
    "times[\"read_input\"] = time() - start\n",
    "G_c = nx.complement(G) # friends graph\n",
    "# nx.draw(G_c, pos=nx.spring_layout(G_c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35f0a9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function\n",
    "def copy_solution(X):\n",
    "    x = dict()\n",
    "    for u in new_nodes:\n",
    "        for p in projects:\n",
    "            x[(u, p)] = X[(u, p)].X\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17366c0a",
   "metadata": {},
   "source": [
    "## Compaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf286779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing isolated nodes ...\n",
      "Finding connected components ...\n",
      "Finding dense subgraphs ...\n",
      "start\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 32\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m cc_tmp\u001b[38;5;241m.\u001b[39mnodes:  \n\u001b[1;32m     31\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 32\u001b[0m         greedy_R \u001b[38;5;241m=\u001b[39m \u001b[43mgreedy_charikar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcc_tmp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mlen\u001b[39m(cc_tmp\u001b[38;5;241m.\u001b[39mnodes))\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m#         greedy_r = exact_densest(cc_tmp)\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/dsd/dsp.py:144\u001b[0m, in \u001b[0;36mgreedy_charikar\u001b[0;34m(Ginput, weight)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgreedy_charikar\u001b[39m(Ginput, weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    125\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;124;03m    Charikar's 1/2 greedy algorithm\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    141\u001b[0m \n\u001b[1;32m    142\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 144\u001b[0m     H, rho, _ \u001b[38;5;241m=\u001b[39m \u001b[43mflowless\u001b[49m\u001b[43m(\u001b[49m\u001b[43mGinput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m H, rho\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/dsd/dsp.py:174\u001b[0m, in \u001b[0;36mflowless\u001b[0;34m(hyper_list, T, weight)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# self.check_undirected_graph(G)\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(hyper_list, nx\u001b[38;5;241m.\u001b[39mGraph):\n\u001b[0;32m--> 174\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mflowless_from_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhyper_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    176\u001b[0m loads \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m()\n\u001b[1;32m    177\u001b[0m loadsstar \u001b[38;5;241m=\u001b[39m loads\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/dsd/dsp.py:226\u001b[0m, in \u001b[0;36mflowless_from_graph\u001b[0;34m(G, T, weight)\u001b[0m\n\u001b[1;32m    224\u001b[0m Hstar \u001b[38;5;241m=\u001b[39m H\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(T):\n\u001b[0;32m--> 226\u001b[0m     node_dict, fibheap, total_degree \u001b[38;5;241m=\u001b[39m \u001b[43minit_heap_flowless_from_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    227\u001b[0m     H, tmp, loads \u001b[38;5;241m=\u001b[39m greedy_helper_from_graph(G, node_dict, fibheap, total_degree, weight\u001b[38;5;241m=\u001b[39mweight)\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# print('iteration ' + repr(i + 1))\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/dsd/dsp.py:341\u001b[0m, in \u001b[0;36minit_heap_flowless_from_graph\u001b[0;34m(G, loads, weight)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    340\u001b[0m     edge_w \u001b[38;5;241m=\u001b[39m G[node][neighbor][weight]\n\u001b[0;32m--> 341\u001b[0m \u001b[43mfibheap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecrease_key\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43medge_w\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    342\u001b[0m node_dict[node][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(neighbor)\n\u001b[1;32m    343\u001b[0m total_degree \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m edge_w\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/dsd/fibheap.py:69\u001b[0m, in \u001b[0;36mFibonacciHeap.decrease_key\u001b[0;34m(self, x, k)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecrease_key\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, k):\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;241m>\u001b[39m x\u001b[38;5;241m.\u001b[39mkey:\n\u001b[0;32m---> 69\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincrease_key\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m     x\u001b[38;5;241m.\u001b[39mkey \u001b[38;5;241m=\u001b[39m k\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/dsd/fibheap.py:101\u001b[0m, in \u001b[0;36mFibonacciHeap.increase_key\u001b[0;34m(self, x, k)\u001b[0m\n\u001b[1;32m     99\u001b[0m right \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mright\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m right \u001b[38;5;241m!=\u001b[39m x:\n\u001b[0;32m--> 101\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_node\u001b[38;5;241m.\u001b[39mkey \u001b[38;5;241m>\u001b[39m right\u001b[38;5;241m.\u001b[39mkey:\n\u001b[1;32m    102\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_node \u001b[38;5;241m=\u001b[39m right\n\u001b[1;32m    103\u001b[0m     right \u001b[38;5;241m=\u001b[39m right\u001b[38;5;241m.\u001b[39mright\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "print('Removing isolated nodes ...')\n",
    "# remove isolated nodes\n",
    "H = nx.complement(G) # copy of friends graph\n",
    "superNodeSize = dict()\n",
    "isolated_nodes = [node for node in H.nodes() if H.degree(node) == 0]\n",
    "new_nodes = isolated_nodes\n",
    "for node in new_nodes:\n",
    "    superNodeSize[node] = 1\n",
    "H.remove_nodes_from(isolated_nodes)\n",
    "\n",
    "print('Finding connected components ...')\n",
    "# find connected components\n",
    "connected_comps = []\n",
    "for comp in list(nx.connected_components(H)):\n",
    "    if len(comp) <= 5: # compacting small components\n",
    "        H.remove_nodes_from(list(comp))\n",
    "        super_node = ','.join(list(comp))\n",
    "        superNodeSize[super_node] = len(list(comp))\n",
    "        new_nodes.append(super_node)\n",
    "    else:\n",
    "        connected_comps.append(H.subgraph(list(comp)))\n",
    "        \n",
    "print('Finding dense subgraphs ...')\n",
    "# Find dense subgraphs in each connected component\n",
    "for cc in connected_comps:\n",
    "    cc_tmp = H.subgraph(cc.nodes)\n",
    "#     cc_tmp.add_nodes_from(cc.nodes)\n",
    "#     cc_tmp.add_edges_from(cc.edges)\n",
    "    while cc_tmp.nodes:  \n",
    "        print('start')\n",
    "        greedy_R = greedy_charikar(cc_tmp)\n",
    "        print('test', len(cc_tmp.nodes))\n",
    "#         greedy_r = exact_densest(cc_tmp)\n",
    "        super_node = \",\".join(greedy_R[0])\n",
    "        superNodeSize[super_node] = len(greedy_R[0])\n",
    "        new_nodes.append(super_node)\n",
    "        cc_tmp.remove_nodes_from(greedy_R[0])\n",
    "        \n",
    "print('Setting up the compact problem ...')\n",
    "Gc_compact = nx.Graph()\n",
    "Gc_compact.add_nodes_from(new_nodes)\n",
    "G_compact = nx.complement(Gc_compact)\n",
    "w_compact = dict()\n",
    "for e in G_compact.edges():\n",
    "    u, v = e\n",
    "    w_compact[e] = superNodeSize[u] * superNodeSize[v]\n",
    "    \n",
    "c_compact = dict()\n",
    "for superNode in new_nodes:\n",
    "    for p in projects:\n",
    "        c_compact[(superNode, p)] = 0\n",
    "\n",
    "for superNode in new_nodes:\n",
    "    simple_nodes = superNode.split(',')\n",
    "    for u in simple_nodes:\n",
    "        for p in projects:\n",
    "            if (u, p) in c:\n",
    "                c_compact[(superNode, p)] += c[(u, p)]\n",
    "times['compaction'] = time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941adcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'# of (compact) conflict edges = {len(G_compact.edges)}')\n",
    "print(f'# of (compact) friend edges = {len(Gc_compact.edges)}')\n",
    "print(f'# of (compact) nodes = {len(G_compact.nodes)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc5f0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "superNodeSize.values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277e52d2",
   "metadata": {},
   "source": [
    "## Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d601660a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function\n",
    "def teams_to_x(teams):\n",
    "    x = dict()\n",
    "    for t in teams:\n",
    "        team = teams[t]\n",
    "        for u in team:\n",
    "            x[(u, t)] = 1\n",
    "    return x\n",
    "\n",
    "def baselines():\n",
    "    # Random\n",
    "    teams_random = {t: [] for t in random.sample(projects, len(projects))}\n",
    "    for u in random.sample(nodes, len(nodes)):\n",
    "        for t in teams_random:\n",
    "            if len(teams_random[t]) < capacities[t]:\n",
    "                teams_random[t].append(u)\n",
    "    x_random = teams_to_x(teams_random)\n",
    "    \n",
    "    # Greedy\n",
    "    teams_greedy = {t: [] for t in projects}\n",
    "    for u in nodes:\n",
    "        t_max = -1\n",
    "        increase = -2**60\n",
    "        for t in teams_greedy:\n",
    "            x_greedy = teams_to_x(teams_greedy)\n",
    "            f_greedy = f(x_greedy)\n",
    "            x_tmp = teams_to_x(teams_greedy)\n",
    "            if len(teams_greedy[t]) < capacities[t]:\n",
    "                x_tmp[(u, t)] = 1\n",
    "                inc = f(x_tmp) - f_greedy\n",
    "                if inc > increase:\n",
    "                    increase = inc\n",
    "                    t_max = t\n",
    "        teams_greedy[t_max].append(u)\n",
    "    x_greedy = teams_to_x(teams_greedy)\n",
    "    \n",
    "    return x_random, x_greedy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbe741a",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51746641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define objective function\n",
    "def f(x):\n",
    "    res = 0\n",
    "    # project preference term\n",
    "    for u in nodes:\n",
    "        for p in projects:\n",
    "            if (u, p) in c and (u, p) in x:\n",
    "                res += c[(u, p)] * x[(u, p)]\n",
    "    res *= lambda_\n",
    "    \n",
    "    # conflict term\n",
    "    for e in edges:\n",
    "        u, v = e\n",
    "        inner_sum = 0\n",
    "        for p in projects:\n",
    "            if (u, p) in x and (v, p) in x:\n",
    "                inner_sum += x[(u, p)] * x[(v, p)]\n",
    "        res += (1 - inner_sum)\n",
    "    return res\n",
    "\n",
    "# Pipage rounding\n",
    "def construct_graph(x):\n",
    "    H = nx.Graph()\n",
    "    H.add_nodes_from(nodes, bipartite=0)\n",
    "    H.add_nodes_from(projects, bipartite=1)\n",
    "    edges = [(u, p) for u in nodes for p in projects if (u, p) in x and not np.isclose(x[(u, p)], 0) and not np.isclose(x[(u, p)], 1)]\n",
    "    H.add_edges_from(edges)\n",
    "    return H\n",
    "\n",
    "def find_cycle(H):\n",
    "    try:\n",
    "        cycle = nx.find_cycle(H)\n",
    "    except Exception:\n",
    "        cycle = []\n",
    "    return cycle\n",
    "\n",
    "def find_path(graph):\n",
    "    def dfs_with_backtracking(vertex, path):\n",
    "        nonlocal max_path\n",
    "        path.append(vertex)\n",
    "\n",
    "        for neighbor in graph[vertex]:\n",
    "            if neighbor not in path:\n",
    "                dfs_with_backtracking(neighbor, path)\n",
    "\n",
    "        if len(path) > len(max_path):\n",
    "            max_path = path.copy()\n",
    "\n",
    "        path.pop()\n",
    "\n",
    "    max_path = []\n",
    "    for start_vertex in graph.nodes:\n",
    "        dfs_with_backtracking(start_vertex, [])\n",
    "        if max_path:\n",
    "            return list(zip(max_path, max_path[1:]))\n",
    "    \n",
    "    print(\"No path found...\")\n",
    "    return max_path\n",
    "\n",
    "def format_path(R):\n",
    "    R_new = deque()\n",
    "    for e in R:\n",
    "        u, p = e if e[0] in nodes else tuple(reversed(e)) # (student, project) edge\n",
    "        R_new.append((u, p))\n",
    "    return list(R_new)\n",
    "\n",
    "def calc_eps(x, R):\n",
    "    # Divide R into M1 and M2 matchings\n",
    "    M1 = R[::2]\n",
    "    M2 = R[1::2]\n",
    "    \n",
    "    # Calculate eps1, eps2\n",
    "    eps1 = min(min([x[e] for e in M1]), min([1 - x[e] for e in M2]))\n",
    "    eps2 = min(min([1 - x[e] for e in M1]), min([x[e] for e in M2]))\n",
    "    \n",
    "    return eps1, eps2, M1, M2\n",
    "\n",
    "def remove_dec_error(x):            \n",
    "    #only keep the keys corresponding to value 1\n",
    "    x_new = dict()\n",
    "    for e in x:\n",
    "        if np.isclose(x[e], 1):\n",
    "            x_new[e] = 1\n",
    "    return x_new\n",
    "\n",
    "def step(x, eps, M1, M2):\n",
    "    x_new = x.copy()\n",
    "    for e in M1:\n",
    "        x_new[e] += eps\n",
    "    for e in M2:\n",
    "        x_new[e] -= eps\n",
    "    return x_new\n",
    "\n",
    "def round(x, eps1, eps2, M1, M2):\n",
    "    x1 = step(x, -eps1, M1, M2)\n",
    "    x2 = step(x, eps2, M1, M2)\n",
    "    if f(x1) > f(x2):\n",
    "        return x1\n",
    "    return x2\n",
    "\n",
    "def rand_round(x, eps1, eps2, M1, M2):\n",
    "    rand = rand = random.uniform(0, 1)\n",
    "    if rand < eps1 / (eps1 + eps2):\n",
    "        x_new = step(x, -eps1, M1, M2)\n",
    "    else:\n",
    "        x_new = step(x, eps2, M1, M2)\n",
    "    return x_new\n",
    "    \n",
    "def clean_edges(x, H):\n",
    "    integral_edges = [e for e in H.edges if np.isclose(x[e], 0) or np.isclose(x[e], 1)]\n",
    "    H.remove_edges_from(integral_edges)\n",
    "    return H\n",
    "        \n",
    "def pipage_help(x, R):\n",
    "    R = format_path(R)\n",
    "    eps1, eps2, M1, M2 = calc_eps(x, R)\n",
    "    x_new = round(x, eps1, eps2, M1, M2)\n",
    "    return x_new\n",
    "\n",
    "def rand_pipage_help(x, R):\n",
    "    R = format_path(R)\n",
    "    eps1, eps2, M1, M2 = calc_eps(x, R)\n",
    "    x_new = rand_round(x, eps1, eps2, M1, M2)\n",
    "    return x_new\n",
    "\n",
    "def pipage(x, setting=\"deterministic\"):\n",
    "    H = construct_graph(x)    \n",
    "    while True:\n",
    "        R = find_cycle(H)\n",
    "        R = R if R else find_path(H)\n",
    "        if len(R) == 1:\n",
    "            print(f'R = {R}')\n",
    "            print(f'x = {x}')\n",
    "        if R and len(R) > 1:\n",
    "            x = pipage_help(x, R) if setting == 'deterministic' else rand_pipage_help(x, R)\n",
    "            clean_edges(x, H)\n",
    "        else:\n",
    "            return remove_dec_error(x)\n",
    "        \n",
    "    print(\"Error: Pipage rounding failed ...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91600c6e",
   "metadata": {},
   "source": [
    "## Solve compacted problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f07e114",
   "metadata": {},
   "outputs": [],
   "source": [
    "def round34():\n",
    "    print(f'Running round34 ...')\n",
    "\n",
    "    start = time()\n",
    "\n",
    "    # Create a new model\n",
    "    m = gp.Model(\"linear\") #, env=env)\n",
    "    m.Params.timeLimit = 300 #timeLimit\n",
    "\n",
    "    print('Creating variables ...')\n",
    "    # Create variables\n",
    "    X = dict()\n",
    "    for u in new_nodes:\n",
    "        for p in projects:\n",
    "            X[(u, p)] = m.addVar(vtype=GRB.CONTINUOUS)\n",
    "\n",
    "    print('Creating auxiliary variables ...')\n",
    "    # Auxiliary variables\n",
    "    Z = dict()\n",
    "    S = dict()\n",
    "    print(f'# of G_compact edges = {len(G_compact.edges())}')\n",
    "    print(f'# of nodes of G_compact = {len(G_compact.nodes())}')\n",
    "    for e in G_compact.edges():\n",
    "        u = e[0]\n",
    "        v = e[1]\n",
    "        for t in projects:\n",
    "            Z[(u, v, t)] = m.addVar(vtype=GRB.CONTINUOUS)\n",
    "            S[(u, v, t)] = m.addVar(vtype=GRB.CONTINUOUS)\n",
    "            m.addConstr(S[(u, v, t)] == X[(u, t)] + X[(v, t)])\n",
    "            m.addConstr(Z[(u, v, t)] == gp.min_(S[(u, v, t)], constant = 1))\n",
    "\n",
    "    print('Adding constraints ...')   \n",
    "    # Add constraints\n",
    "    # Each student assigned to exactly one project\n",
    "    for u in new_nodes:\n",
    "        expr = gp.LinExpr(numOfProjects*[1], [X[(u, t)] for t in projects])\n",
    "        m.addConstr(expr == 1)\n",
    "\n",
    "    # Project capacity constraints\n",
    "    for p in projects:\n",
    "        expr = gp.LinExpr([superNodeSize[u] for u in new_nodes], [X[(u, p)] for u in new_nodes])\n",
    "        m.addConstr(expr <= capacities[p])\n",
    "\n",
    "    # Relaxed objective L(x)\n",
    "    L = gp.LinExpr()\n",
    "\n",
    "    # Linear (project preference) term\n",
    "    for u in new_nodes:\n",
    "        for p in projects:\n",
    "            if (u, p) in c_compact:\n",
    "                L += c_compact[(u, p)] * X[(u, p)]\n",
    "    L *= lambda_\n",
    "\n",
    "    # Max-cut term\n",
    "    for e in G_compact.edges():\n",
    "        u = e[0]; v = e[1]\n",
    "        for p in projects:\n",
    "            L += w_compact[(u, v)] * Z[(u, v, p)] \n",
    "            \n",
    "    L -= sum(w_compact.values())\n",
    "\n",
    "    m.setObjective(L, GRB.MAXIMIZE)    \n",
    "    times[\"relax_model34\"] = time() - start\n",
    "\n",
    "    print(f'Optimizing ...')\n",
    "    start = time()\n",
    "    # Optimize model\n",
    "    m.optimize()\n",
    "\n",
    "    # Convert solution to dictionary format\n",
    "    x_frac34 = copy_solution(X)\n",
    "    times[\"optimize_relaxation34\"] = time() - start\n",
    "\n",
    "    return x_frac34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951779aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_mul = 1\n",
    "lambda_ = lambda_mul * sum(w_compact.values()) / n\n",
    "x_frac34 = round34()\n",
    "x_frac12 = round12()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3964548",
   "metadata": {},
   "source": [
    "## Unroll solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d6605e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unroll(x_compact):\n",
    "    x_unroll = dict()\n",
    "    for e in x_compact:\n",
    "        superNode, p = e\n",
    "        simple_nodes = superNode.split(',')\n",
    "        for u in simple_nodes:\n",
    "            if x_compact[e] != 0:\n",
    "                x_unroll[(u, p)] = x_compact[e]\n",
    "    return x_unroll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96676e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_unroll34 = unroll(x_frac34)\n",
    "x_unroll12 = unroll(x_frac12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7c9aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_teams(x):\n",
    "    teams = dict()\n",
    "    for p in projects:\n",
    "        teams[p] = []\n",
    "\n",
    "    for e in x:\n",
    "        u, p = e\n",
    "        if x[e] == 1:\n",
    "            u, p = e\n",
    "            teams[p].append(u)\n",
    "            \n",
    "    for p in projects:\n",
    "        teams[p].sort()\n",
    "        \n",
    "    return teams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f936a9fd",
   "metadata": {},
   "source": [
    "## Round solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3320ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Rounding 3/4 solution ...')\n",
    "start = time()\n",
    "x_round34 = pipage(x_unroll34, 'randomized')\n",
    "times['rounding_34'] = time() - start\n",
    "# print('Rounding 1/2 solution ...')\n",
    "# start = time()\n",
    "# x_round12 = pipage(x_unroll12, 'deterministic')\n",
    "# times['rounding_12'] = time() - start\n",
    "print('Constructing teams ...')\n",
    "teams34 = construct_teams(x_round34)\n",
    "# teams12 = construct_teams(x_round12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5c953a",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_34 = f(x_round34)\n",
    "times\n",
    "# val_12 = f(x_round12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55a9044",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_random, x_greedy = baselines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdc57bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_random, val_greedy = f(x_random), f(x_greedy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4104350b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36715c33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
